# AuenBot
Migration from LUBW/NAZKA ChatBot KarlA


# Status

Analyzed dataset from LUBW

Extracted chatbot signatures for intents and responses 

Extracted data from plants, animals and Rheinauen" area

Intents also relate to access to current whether conditions and environmental data. 

Initial decoding and routing implemented in python. Input matching with rapidfuzz (text matchin library). 
Fallback to remote LLM if required.
Options for vector-search but initial version with BM25 not very helpfull. Future test with bge-m3 pending (vectors from intent samples already generated).


## RawData

### Primary files
  * tiere_pflanzen_auen.json: knowledge base. dataset for animals, plants and some Rheinauen types.
  * intents.json: intents with sample texts and utterance (if any)
  * intent_vectors.json: vectorized (bge-m3 embeddings) text samples and corresponding intent_id. **Needs git lfs**

### Original bot
  * tagsAndInstructions.json: additional info for original bot decoding and routing

### Intent detection

  1) Find "simple" intents, which ,ap to one specific answer, like *wo gibt es etwas zu essen?*
  2) Find "simple" intents which require function calling, like *wie ist der CO2 Gehalt?*
  3) Find intents which require specific information, usually acquired during multiple steps using a more or less complex context. 
    * Travel information with from,to,date
    * Entity (Tiere, Pflanzen, Auen) information using various key parameters (properties, class, type), like so (from original):

```python
    > tp_generell_extract_information(latest_msg):result_matching = process.extractOne(latest_msg, animal_categories)
  if result_matching[1] > 80
      result[0] = result_matching[0]
  else result_matching = process.extractOne(latest_msg, ["Tiere", "Pflanzen", "B\u00e4ume", "Blumen"])
      if result_matching[1] > 80
          if result_matching[0] == "Tiere":result[0] = "Tiere" 
          else result[0] = "Pflanzen" result_matching = process.extractOne(latest_msg, lr_categories)
              if result_matching[1] > 80
                  result[1] = result_matching[0]
                      current_lr = result[1]
                      return result
                      
  def tp_generell_generate_answer(entities):
  result = []
  if entities[0] == "Tiere":
      for animal in ANIMAL.keys():
          if not entities[1] or lr_categories.index(entities[1]) in ANIMAL[animal][4]:
              result.append(animal)
          elif entities[0] == "Pflanzen"
              for plant in PLANT.keys()
                  if not entities[1] or lr_categories.index(entities[1]) in PLANT[plant][4]:
                      result.append(plant)
                  else:
                      for animal in ANIMAL.keys()
                          if ANIMAL[animal][3] == str(animal_categories.index(entities[0])):
                              if not entities[1] or lr_categories.index(entities[1]) in ANIMAL[animal][4]:
                                  result.append(animal)
  return result

```



### Auxiliary, input or leftover files
  * pflanzenKeys.json: Parameters for plant descriptions 
  * tiereKeys.json: Parameters for animal descriptions 
  * taskList.json: decoded signatures. if *utter* is present, it should be used as response. Otherwise, intent should either start with *tp_*, *tiere_*, *pflanzen_*  which should then address the data from the corresponding types (or both), or with *wetter* or *messdaten*.  Reference to the few *Rheinauen* datasets has to be defined still.

## Media

### Directory of fantasy images
512*512, generated by flux-1-schnell.



## Next Steps
### Basic Bot
Create vector embedding for all intent texts. Setup database with vectors, full text and intent names. Test chatbot response to arbitrary requests. 

### Reference Data

Add data access to whether conditions, environmental data, Wikidata images and audio files, Source to be found, probably from NAZKA, or https://www.museumfuernaturkunde.berlin/de/forschung/tierstimmenarchiv. MP3 files were missing in input dataset.

